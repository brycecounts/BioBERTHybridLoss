{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "A100"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "#install dependencies\n",
        "!pip install --upgrade pip\n",
        "!pip install --quiet --upgrade nltk\n",
        "!pip install --quiet --upgrade nlpaug\n",
        "!pip install --quiet --upgrade datasets transformers sentencepiece torch torchvision torchaudio\n",
        "!pip install --quiet --upgrade scikit-learn\n",
        "!pip install --quiet --upgrade geomloss\n",
        "!pip install --quiet --upgrade seaborn matplotlib\n",
        "!pip install transformers matplotlib seaborn"
      ],
      "metadata": {
        "id": "lSSB1agD5x-9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#imports\n",
        "import os\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "import nltk\n",
        "nltk.download('averaged_perceptron_tagger')\n",
        "nltk.download('wordnet')\n",
        "nltk.download('punkt')"
      ],
      "metadata": {
        "id": "rL4FUo_h51YQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#patching and pos tagging\n",
        "from nlpaug.model.word_dict.wordnet import WordNet as NlpaugWordNet\n",
        "\n",
        "def forced_pos_tag(self, tokens, tagset=None, lang=None):\n",
        "    \"\"\"\n",
        "    Robust POS tagging with enhanced debugging for invalid cases.\n",
        "    \"\"\"\n",
        "    import nltk\n",
        "\n",
        "    # Tokenize if tokens is a string\n",
        "    if isinstance(tokens, str):\n",
        "        tokens = nltk.word_tokenize(tokens)\n",
        "    elif isinstance(tokens, list):\n",
        "        tokens = [str(token) for token in tokens]\n",
        "    else:\n",
        "        print(f\"[WARN] Invalid input to pos_tag: {tokens}\")\n",
        "        return []\n",
        "\n",
        "    if not tokens:\n",
        "        print(\"[WARN] Empty tokens encountered. Skipping...\")\n",
        "        return []\n",
        "\n",
        "    try:\n",
        "        return nltk.pos_tag(tokens, tagset=tagset)\n",
        "    except Exception as e:\n",
        "        print(f\"[ERROR] POS tagging failed. Tokens: {tokens} | Error: {e}\")\n",
        "        return []\n",
        "\n",
        "NlpaugWordNet.pos_tag = forced_pos_tag"
      ],
      "metadata": {
        "id": "WPGjuIfy548t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#rest of imports\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "from datasets import load_dataset\n",
        "from transformers import AutoTokenizer, AutoModel\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import (\n",
        "    classification_report, f1_score, precision_score,\n",
        "    recall_score, roc_auc_score, confusion_matrix\n",
        ")\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "from geomloss import SamplesLoss\n",
        "import nlpaug.augmenter.word as naw"
      ],
      "metadata": {
        "id": "-H9IYItr59nM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#device config\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(f\"Using device: {device}\")"
      ],
      "metadata": {
        "id": "bWrHbRoU6BVL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#load dataset\n",
        "raw_dataset = load_dataset(\"bigbio/bionlp_st_2013_ge\", \"bionlp_st_2013_ge_source\")\n",
        "print(raw_dataset)\n",
        "\n",
        "train_data = raw_dataset['train']\n",
        "val_data   = raw_dataset['validation']\n",
        "test_data  = raw_dataset['test']\n",
        "full_data  = list(train_data) + list(val_data) + list(test_data)"
      ],
      "metadata": {
        "id": "nr0cySOA6Ecj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#parse\n",
        "rows = []\n",
        "for sample in full_data:\n",
        "    doc_text = sample.get('text', \"\")\n",
        "    events = sample.get('events', [])\n",
        "    if not events or not doc_text.strip():\n",
        "        continue\n",
        "\n",
        "    for evt in events:\n",
        "        evt_type = evt.get('type', \"\")\n",
        "        if evt_type == \"Phosphorylation\":\n",
        "            action = \"Phosphorylation\"\n",
        "        elif evt_type == \"Positive_regulation\":\n",
        "            action = \"Activation\"\n",
        "        elif evt_type == \"Negative_regulation\":\n",
        "            action = \"Inhibition\"\n",
        "        else:\n",
        "            continue\n",
        "\n",
        "        trigger_info = evt.get('trigger', \"\")\n",
        "        trigger_text = (trigger_info.get('text', \"\").strip() if isinstance(trigger_info, dict)\n",
        "                        else str(trigger_info).strip())\n",
        "        if not trigger_text:\n",
        "            continue\n",
        "\n",
        "        arguments = evt.get('arguments', [])\n",
        "        arg_texts = [arg.get('text', \"\").strip() for arg in arguments if isinstance(arg, dict)]\n",
        "        entityB = \" | \".join(arg_texts) if arg_texts else \"None\"\n",
        "\n",
        "        truncated_doc = doc_text[:1500]\n",
        "        description = f\"TRIGGER: {trigger_text} | DOC: {truncated_doc}\"\n",
        "\n",
        "        rows.append({\n",
        "            \"ENTITYA\": trigger_text,\n",
        "            \"ENTITYB\": entityB,\n",
        "            \"ACTION\": action,\n",
        "            \"DESCRIPTION\": description,\n",
        "        })\n",
        "\n",
        "df = pd.DataFrame(rows).dropna(subset=['DESCRIPTION']).reset_index(drop=True)\n",
        "print(\"\\nParsed\", len(df), \"total events.\")\n",
        "print(df['ACTION'].value_counts())\n",
        "\n"
      ],
      "metadata": {
        "id": "JPPyg2Yw6ItN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#split then augment only train\n",
        "\n",
        "label_map = {\"Inhibition\": 0, \"Activation\": 1, \"Phosphorylation\": 2}\n",
        "df['label_idx'] = df['ACTION'].map(label_map)\n",
        "\n",
        "train_df, temp_df = train_test_split(df, test_size=0.3, stratify=df['label_idx'], random_state=42)\n",
        "val_df, test_df = train_test_split(temp_df, test_size=0.5, stratify=temp_df['label_idx'], random_state=42)\n",
        "\n",
        "print(\"\\nOriginal Training Size:\", len(train_df))\n",
        "print(\"Validation Size:\", len(val_df))\n",
        "print(\"Test Size:\", len(test_df))"
      ],
      "metadata": {
        "id": "BGNqRACI6MwH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#synonym augmentation\n",
        "aug = naw.SynonymAug(aug_src='wordnet')\n",
        "\n",
        "def synonym_augment_data(subdf, label, num_aug=1):\n",
        "    new_records = []\n",
        "    for _ in range(num_aug):\n",
        "        for entA, entB, desc in zip(subdf['ENTITYA'], subdf['ENTITYB'], subdf['DESCRIPTION']):\n",
        "            combined_str = f\"{entA} {entB} {desc}\"\n",
        "            if not combined_str.strip():\n",
        "                continue\n",
        "            aug_text = aug.augment(combined_str, n=1)\n",
        "            if isinstance(aug_text, list):\n",
        "                aug_text = aug_text[0]\n",
        "            new_records.append({\n",
        "                \"ENTITYA\": entA,\n",
        "                \"ENTITYB\": entB,\n",
        "                \"ACTION\": label,\n",
        "                \"DESCRIPTION\": aug_text\n",
        "            })\n",
        "    return pd.DataFrame(new_records)\n",
        "\n",
        "def apply_synonym_augmentation(train_df):\n",
        "    max_class = train_df['ACTION'].value_counts().max()\n",
        "    augmented_frames = []\n",
        "    for label in train_df['ACTION'].unique():\n",
        "        subdf = train_df[train_df['ACTION'] == label]\n",
        "        times = max(0, (max_class // len(subdf)) - 1)\n",
        "        if times > 0:\n",
        "            aug_df = synonym_augment_data(subdf, label, num_aug=times)\n",
        "            augmented_frames.append(aug_df)\n",
        "    if augmented_frames:\n",
        "        train_df = pd.concat([train_df] + augmented_frames, ignore_index=True)\n",
        "    return train_df\n",
        "\n",
        "train_df = apply_synonym_augmentation(train_df)\n",
        "print(\"\\nAfter Synonym Augmentation, Train Size:\", len(train_df))"
      ],
      "metadata": {
        "id": "vr19vJdw6dww"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#label encoding and class weighting\n",
        "\n",
        "train_df['effect_encoded'] = train_df['ACTION'].map(label_map)\n",
        "val_df['effect_encoded']   = val_df['ACTION'].map(label_map)\n",
        "test_df['effect_encoded']  = test_df['ACTION'].map(label_map)\n",
        "\n",
        "unique_labels = [\"Inhibition\", \"Activation\", \"Phosphorylation\"]\n",
        "num_classes = len(unique_labels)\n",
        "\n",
        "\n",
        "assert train_df['effect_encoded'].min() >= 0 and train_df['effect_encoded'].max() < num_classes, \"Label out of range!\"\n",
        "\n",
        "\n",
        "counts_array = np.array([len(train_df[train_df['effect_encoded'] == i]) for i in range(num_classes)])\n",
        "print(\"Class counts:\", counts_array)\n",
        "\n",
        "\n",
        "epsilon = 1e-8\n",
        "beta = 0.9999\n",
        "effective_num = 1.0 - np.power(beta, counts_array) + epsilon\n",
        "weights = (1.0 - beta) / effective_num\n",
        "weights = weights / np.sum(weights) * num_classes\n",
        "\n",
        "\n",
        "class_weights = torch.tensor(weights, dtype=torch.float32, device=device)\n",
        "torch.cuda.synchronize()\n",
        "print(\"Class weights:\", class_weights)\n",
        "\n",
        "print(\"\\nTrain Class Distribution:\\n\", train_df['ACTION'].value_counts())\n",
        "print(\"\\nVal Class Distribution:\\n\", val_df['ACTION'].value_counts())\n",
        "print(\"\\nTest Class Distribution:\\n\", test_df['ACTION'].value_counts())\n"
      ],
      "metadata": {
        "id": "SUg-UBEQ6jGT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#tokenizer\n",
        "model_name = \"dmis-lab/biobert-base-cased-v1.1\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)"
      ],
      "metadata": {
        "id": "910pyjk16qhY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#define dataset class\n",
        "class TextDataset(Dataset):\n",
        "    def __init__(self, df, tokenizer, max_length=256):\n",
        "        self.df = df.reset_index(drop=True)\n",
        "        self.tokenizer = tokenizer\n",
        "        self.max_length = max_length\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.df)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        row = self.df.iloc[idx]\n",
        "        text = row['DESCRIPTION']\n",
        "        label = row['effect_encoded']\n",
        "        if not isinstance(text, str):\n",
        "            text = str(text)\n",
        "        enc = self.tokenizer.encode_plus(\n",
        "            text,\n",
        "            add_special_tokens=True,\n",
        "            truncation=True,\n",
        "            max_length=self.max_length,\n",
        "            padding='max_length',\n",
        "            return_attention_mask=True,\n",
        "            return_tensors='pt'\n",
        "        )\n",
        "        return {\n",
        "            'input_ids': enc['input_ids'].flatten(),\n",
        "            'attention_mask': enc['attention_mask'].flatten(),\n",
        "            'labels': torch.tensor(label, dtype=torch.long)\n",
        "        }\n",
        "\n",
        "train_dataset = TextDataset(train_df, tokenizer)\n",
        "val_dataset   = TextDataset(val_df, tokenizer)\n",
        "test_dataset  = TextDataset(test_df, tokenizer)\n",
        "\n",
        "#BATCH SIZE\n",
        "batch_size = 64\n",
        "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=2)\n",
        "val_loader   = DataLoader(val_dataset, batch_size=batch_size, shuffle=False, num_workers=2)\n",
        "test_loader  = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, num_workers=2)"
      ],
      "metadata": {
        "id": "ncdBiV8B6sxY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#define biobert model with classification head\n",
        "class ClassificationModel(nn.Module):\n",
        "    def __init__(self, num_classes):\n",
        "        super(ClassificationModel, self).__init__()\n",
        "        self.base_model = AutoModel.from_pretrained(model_name)\n",
        "        self.dropout = nn.Dropout(0.6)\n",
        "        self.classifier = nn.Linear(self.base_model.config.hidden_size, num_classes)\n",
        "        #FREEZE LAYERS\n",
        "        for param in self.base_model.encoder.layer[:10].parameters():\n",
        "            param.requires_grad = False\n",
        "\n",
        "    def forward(self, input_ids, attention_mask):\n",
        "        outputs = self.base_model(input_ids=input_ids, attention_mask=attention_mask)\n",
        "        pooled_output = outputs.last_hidden_state[:, 0]  # CLS token\n",
        "        pooled_output = self.dropout(pooled_output)\n",
        "        logits = self.classifier(pooled_output)\n",
        "        return logits\n",
        "\n",
        "\n",
        "classification_model = ClassificationModel(num_classes).to(device)"
      ],
      "metadata": {
        "id": "bVeFlD0D6ye4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#LOSS FUNCTION\n",
        "class FocalLoss(nn.Module):\n",
        "    def __init__(self, alpha=None, gamma=1.5, reduction='mean'):\n",
        "        super(FocalLoss, self).__init__()\n",
        "        self.alpha = alpha\n",
        "        self.gamma = gamma\n",
        "        self.reduction = reduction\n",
        "\n",
        "    def forward(self, logits, targets):\n",
        "        ce_loss = nn.CrossEntropyLoss(weight=self.alpha, reduction='none')(logits, targets)\n",
        "        pt = torch.exp(-ce_loss)\n",
        "        focal_loss = ((1 - pt) ** self.gamma) * ce_loss\n",
        "        if self.reduction == 'mean':\n",
        "            return torch.mean(focal_loss)\n",
        "        elif self.reduction == 'sum':\n",
        "            return torch.sum(focal_loss)\n",
        "        else:\n",
        "            return focal_loss\n",
        "\n",
        "focal_loss_fn = FocalLoss(alpha=class_weights, gamma=1.5)\n",
        "\n",
        "sinkhorn_loss_fn = SamplesLoss(\n",
        "    loss=\"sinkhorn\",\n",
        "    p=2,\n",
        "    blur=0.05,\n",
        "    scaling=0.8,\n",
        "    debias=False\n",
        ")\n",
        "\n",
        "def bubble_wass_loss(logits, labels):\n",
        "    fl_loss = focal_loss_fn(logits, labels)\n",
        "    epsilon = 0.1\n",
        "    n_cls = logits.size(1)\n",
        "\n",
        "    labels_one_hot = nn.functional.one_hot(labels, num_classes=n_cls).float()\n",
        "    labels_smooth = labels_one_hot * (1 - epsilon) + (epsilon / n_cls)\n",
        "\n",
        "    probs = nn.functional.softmax(logits, dim=1)\n",
        "    B = probs.size(0)\n",
        "\n",
        "    cost_map = {0: 0.0, 1: 2.0, 2: 3.0}\n",
        "    support_vals = [cost_map[i] for i in range(n_cls)]\n",
        "    support = torch.tensor(support_vals, dtype=torch.float32, device=device).unsqueeze(1)\n",
        "    support_batch = support.unsqueeze(0).expand(B, n_cls, 1).contiguous()\n",
        "\n",
        "    a = labels_smooth.unsqueeze(-1).contiguous()\n",
        "    b = probs.unsqueeze(-1).contiguous()\n",
        "\n",
        "    wass_distance = sinkhorn_loss_fn(support_batch, support_batch, a, b)\n",
        "    wass_distance = wass_distance.mean()\n",
        "\n",
        "    total_loss = fl_loss + 1 * wass_distance\n",
        "    return total_loss"
      ],
      "metadata": {
        "id": "DGFQnTaX64_u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#optimizer and scheduleroptimizer = torch.optim.AdamW(\n",
        "optimizer = torch.optim.AdamW(\n",
        "    classification_model.parameters(), lr=2e-5, weight_decay=1e-3\n",
        ")\n",
        "epochs = 10\n",
        "total_steps = len(train_loader) * epochs\n",
        "\n",
        "from torch.optim.lr_scheduler import CosineAnnealingLR\n",
        "scheduler = CosineAnnealingLR(optimizer, T_max=total_steps, eta_min=0)"
      ],
      "metadata": {
        "id": "RBgoYUD_69iR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#train and eval\n",
        "def train_epoch(model, data_loader, optimizer, scheduler):\n",
        "    model.train()\n",
        "    losses = []\n",
        "    correct_predictions = 0\n",
        "    for batch in data_loader:\n",
        "        optimizer.zero_grad()\n",
        "        input_ids = batch['input_ids'].to(device)\n",
        "        attention_mask = batch['attention_mask'].to(device)\n",
        "        labels = batch['labels'].to(device)\n",
        "\n",
        "        logits = model(input_ids, attention_mask)\n",
        "        loss = bubble_wass_loss(logits, labels)\n",
        "\n",
        "        _, preds = torch.max(logits, dim=1)\n",
        "        correct_predictions += torch.sum(preds == labels)\n",
        "        losses.append(loss.item())\n",
        "\n",
        "        loss.backward()\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
        "        optimizer.step()\n",
        "        scheduler.step()\n",
        "\n",
        "    return correct_predictions.double() / len(data_loader.dataset), np.mean(losses)\n",
        "\n",
        "def eval_model(model, data_loader):\n",
        "    model.eval()\n",
        "    losses = []\n",
        "    correct_predictions = 0\n",
        "    all_labels = []\n",
        "    all_preds = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for batch in data_loader:\n",
        "            input_ids = batch['input_ids'].to(device)\n",
        "            attention_mask = batch['attention_mask'].to(device)\n",
        "            labels = batch['labels'].to(device)\n",
        "\n",
        "            logits = model(input_ids, attention_mask)\n",
        "            loss = bubble_wass_loss(logits, labels)\n",
        "\n",
        "            _, preds = torch.max(logits, dim=1)\n",
        "            correct_predictions += torch.sum(preds == labels)\n",
        "            losses.append(loss.item())\n",
        "\n",
        "            all_labels.extend(labels.cpu().numpy())\n",
        "            all_preds.extend(preds.cpu().numpy())\n",
        "\n",
        "    f1 = f1_score(all_labels, all_preds, average='weighted')\n",
        "    return correct_predictions.double() / len(data_loader.dataset), np.mean(losses), f1"
      ],
      "metadata": {
        "id": "RtEzoxTN7EhZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#training loop\n",
        "history = {\n",
        "    'train_acc': [],\n",
        "    'train_loss': [],\n",
        "    'val_acc': [],\n",
        "    'val_loss': [],\n",
        "    'val_f1': []\n",
        "}\n",
        "\n",
        "best_val_f1 = 0\n",
        "num_epochs = 2\n",
        "epochs_no_improve = 3\n",
        "patience = 10\n",
        "\n",
        "classification_model.eval()\n",
        "train_acc_init, train_loss_init, train_f1_init = eval_model(classification_model, train_loader)\n",
        "val_acc_init, val_loss_init, val_f1_init = eval_model(classification_model, val_loader)\n",
        "\n",
        "history['train_acc'].append(train_acc_init.item())\n",
        "history['train_loss'].append(train_loss_init)\n",
        "history['val_acc'].append(val_acc_init.item())\n",
        "history['val_loss'].append(val_loss_init)\n",
        "history['val_f1'].append(val_f1_init)\n",
        "\n",
        "print(\"Initial (Epoch 0) Metrics:\")\n",
        "print(f\"Train Accuracy: {train_acc_init:.4f}, Train Loss: {train_loss_init:.4f}\")\n",
        "print(f\"Val Accuracy:   {val_acc_init:.4f}, Val Loss: {val_loss_init:.4f}, Val F1: {val_f1_init:.4f}\")\n",
        "\n",
        "for epoch in range(1, num_epochs + 1):\n",
        "    classification_model.train()\n",
        "    train_loss_sum = 0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "\n",
        "    for batch in train_loader:\n",
        "        inputs = batch['input_ids'].to(device)\n",
        "        attention_mask = batch['attention_mask'].to(device)\n",
        "        labels = batch['labels'].to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        outputs = classification_model(inputs, attention_mask)\n",
        "        loss = bubble_wass_loss(outputs, labels)\n",
        "\n",
        "        loss.backward()\n",
        "        torch.nn.utils.clip_grad_norm_(classification_model.parameters(), max_norm=1.0)\n",
        "        optimizer.step()\n",
        "\n",
        "        train_loss_sum += loss.item()\n",
        "        _, predicted = torch.max(outputs, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "    train_accuracy = correct / total\n",
        "    avg_train_loss = train_loss_sum / len(train_loader)\n",
        "\n",
        "    classification_model.eval()\n",
        "    val_loss_sum = 0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    all_labels = []\n",
        "    all_preds = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for batch in val_loader:\n",
        "            inputs = batch['input_ids'].to(device)\n",
        "            attention_mask = batch['attention_mask'].to(device)\n",
        "            labels = batch['labels'].to(device)\n",
        "\n",
        "            outputs = classification_model(inputs, attention_mask)\n",
        "            loss = bubble_wass_loss(outputs, labels)\n",
        "            val_loss_sum += loss.item()\n",
        "\n",
        "            _, predicted = torch.max(outputs, 1)\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "\n",
        "            all_labels.extend(labels.cpu().numpy())\n",
        "            all_preds.extend(predicted.cpu().numpy())\n",
        "\n",
        "    validation_accuracy = correct / total\n",
        "    avg_val_loss = val_loss_sum / len(val_loader)\n",
        "    val_f1 = f1_score(all_labels, all_preds, average='weighted')\n",
        "\n",
        "    history['train_acc'].append(train_accuracy)\n",
        "    history['train_loss'].append(avg_train_loss)\n",
        "    history['val_acc'].append(validation_accuracy)\n",
        "    history['val_loss'].append(avg_val_loss)\n",
        "    history['val_f1'].append(val_f1)\n",
        "\n",
        "    print(f\"\\nEpoch {epoch}/{num_epochs}\")\n",
        "    print(f\"Train Loss: {avg_train_loss:.4f}, Train Accuracy: {train_accuracy:.4f}\")\n",
        "    print(f\"Validation Loss: {avg_val_loss:.4f}, Validation Accuracy: {validation_accuracy:.4f}, Validation F1: {val_f1:.4f}\")\n",
        "\n",
        "    if val_f1 > best_val_f1:\n",
        "        best_val_f1 = val_f1\n",
        "        epochs_no_improve = 0\n",
        "        torch.save(classification_model.state_dict(), 'best_model_state.bin')\n",
        "    else:\n",
        "        epochs_no_improve += 1\n",
        "        if patience and epochs_no_improve >= patience:\n",
        "            print(\"Early stopping triggered.\")\n",
        "            break\n",
        "\n",
        "classification_model.load_state_dict(torch.load('best_model_state.bin'))"
      ],
      "metadata": {
        "id": "goZYj6RO7KDW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#val and plot\n",
        "y_true, y_pred, y_probs = [], [], []\n",
        "with torch.no_grad():\n",
        "    for batch in test_loader:\n",
        "        input_ids = batch['input_ids'].to(device)\n",
        "        attention_mask = batch['attention_mask'].to(device)\n",
        "        labels = batch['labels'].to(device)\n",
        "\n",
        "        logits = classification_model(input_ids, attention_mask)\n",
        "        probs = nn.functional.softmax(logits, dim=1)\n",
        "        _, preds = torch.max(logits, dim=1)\n",
        "\n",
        "        y_true.extend(labels.cpu().numpy())\n",
        "        y_pred.extend(preds.cpu().numpy())\n",
        "        y_probs.extend(probs.cpu().numpy())\n",
        "\n",
        "print(\"\\nClassification Report (Test Set):\")\n",
        "print(classification_report(y_true, y_pred, target_names=unique_labels))\n",
        "\n",
        "f1 = f1_score(y_true, y_pred, average='weighted')\n",
        "precision = precision_score(y_true, y_pred, average='weighted')\n",
        "recall = recall_score(y_true, y_pred, average='weighted')\n",
        "print(f\"F1 Score: {f1:.4f}\")\n",
        "print(f\"Precision: {precision:.4f}\")\n",
        "print(f\"Recall: {recall:.4f}\")\n",
        "\n",
        "from sklearn.preprocessing import label_binarize\n",
        "from sklearn.metrics import roc_auc_score\n",
        "\n",
        "y_test_binarized = label_binarize(y_true, classes=range(num_classes))\n",
        "y_probs = np.array(y_probs)\n",
        "if num_classes > 2:\n",
        "    auc = roc_auc_score(y_test_binarized, y_probs, average='weighted', multi_class='ovr')\n",
        "else:\n",
        "    auc = roc_auc_score(y_test_binarized.ravel(), y_probs[:, 1].ravel())\n",
        "print(f\"AUC: {auc:.4f}\")\n",
        "\n",
        "cm = confusion_matrix(y_true, y_pred)\n",
        "plt.figure(figsize=(6, 5))\n",
        "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n",
        "            xticklabels=unique_labels,\n",
        "            yticklabels=unique_labels)\n",
        "plt.title(\"Confusion Matrix (Test)\")\n",
        "plt.xlabel(\"Predicted\")\n",
        "plt.ylabel(\"True\")\n",
        "plt.show()\n",
        "\n",
        "plt.figure(figsize=(8, 5))\n",
        "plt.plot(history['train_acc'], label='Train Accuracy')\n",
        "plt.plot(history['val_acc'], label='Validation Accuracy')\n",
        "plt.title('Accuracy Over Epochs (Epoch 0 = initial eval)')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "plt.figure(figsize=(8, 5))\n",
        "plt.plot(history['train_loss'], label='Train Loss')\n",
        "plt.plot(history['val_loss'], label='Validation Loss')\n",
        "plt.title('Loss Over Epochs (Epoch 0 = initial eval)')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "plt.figure(figsize=(8, 5))\n",
        "plt.plot(history['val_f1'], label='Validation F1 Score')\n",
        "plt.title('Validation F1 Score Over Epochs (Epoch 0 = initial eval)')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('F1 Score')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "print(\"\\nFinal Training Distribution:\\n\", train_df['ACTION'].value_counts())\n"
      ],
      "metadata": {
        "id": "kE9Q8MkW7NYG"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}